{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790e661c",
   "metadata": {},
   "source": [
    "\n",
    "# Fine-tuning\n",
    "\n",
    "This tutorial explains how to fine-tune the `GR00T-N1` pretrained checkpoint on a post-training dataset of the same embodiment. This demonstrates the benefits of post-training, transforming a general model into a specialist model and showing performance improvements.\n",
    "\n",
    "In this tutorial, we will use the demonstration dataset `robot_sim.PickNPlace` from the [demo_data](./demo_data) folder.\n",
    "\n",
    "We will first load the pretrained model and evaluate it on the dataset. Then we will fine-tune the model on the dataset and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be53ee",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687aed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gr00t.utils.eval import calc_mse_for_single_trajectory\n",
    "import warnings\n",
    "from gr00t.experiment.data_config import DATA_CONFIG_MAP\n",
    "from gr00t.model.policy import Gr00tPolicy\n",
    "from gr00t.data.schema import EmbodimentTag\n",
    "from gr00t.data.dataset import LeRobotSingleDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_PATH = \"nvidia/GR00T-N1-2B\"\n",
    "EMBODIMENT_TAG = EmbodimentTag.GR1\n",
    "DATASET_PATH = \"../demo_data/robot_sim.PickNPlace\"\n",
    "\n",
    "\n",
    "data_config = DATA_CONFIG_MAP[\"gr1_arms_only\"]\n",
    "modality_config = data_config.modality_config()\n",
    "modality_transform = data_config.transform()\n",
    "\n",
    "\n",
    "pre_trained_policy = Gr00tPolicy(\n",
    "    model_path=PRE_TRAINED_MODEL_PATH,\n",
    "    embodiment_tag=EMBODIMENT_TAG,\n",
    "    modality_config=modality_config,\n",
    "    modality_transform=modality_transform,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = LeRobotSingleDataset(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    modality_configs=modality_config,\n",
    "    video_backend=\"decord\",\n",
    "    video_backend_kwargs=None,\n",
    "    transforms=None,  # We'll handle transforms separately through the policy\n",
    "    embodiment_tag=EMBODIMENT_TAG,\n",
    ")\n",
    "\n",
    "\n",
    "mse = calc_mse_for_single_trajectory(\n",
    "    pre_trained_policy,\n",
    "    dataset,\n",
    "    traj_id=0,\n",
    "    modality_keys=[\"right_arm\", \"right_hand\"],   # we will only evaluate the right arm and right hand\n",
    "    steps=150,\n",
    "    action_horizon=16,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "print(\"MSE loss for trajectory 0:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805e49a",
   "metadata": {},
   "source": [
    "Great! We can see the predicted actions and the ground truth actions. The predicted actions are not perfect, but they are close to the ground truth actions. This indicates that the pretrained checkpoint works well.\n",
    "\n",
    "Now let's randomly sample 10 trajectories and calculate the average MSE to get more detailed results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fcf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trajectories = len(dataset.trajectory_lengths)\n",
    "\n",
    "print(\"Total trajectories:\", total_trajectories)\n",
    "\n",
    "sampled_trajectories = np.random.choice(total_trajectories, 10)\n",
    "print(\"Sampled trajectories:\", sampled_trajectories)\n",
    "\n",
    "all_mses = []\n",
    "\n",
    "for traj_id in sampled_trajectories:\n",
    "    mse = calc_mse_for_single_trajectory(\n",
    "        pre_trained_policy,\n",
    "        dataset,\n",
    "        traj_id=traj_id,\n",
    "        modality_keys=[\"right_arm\", \"right_hand\"],   # we will only evaluate the right arm and right hand\n",
    "        steps=150,\n",
    "        action_horizon=16,\n",
    "        plot=False\n",
    "    )\n",
    "    print(f\"Trajectory {traj_id} MSE: {mse:.4f}\")\n",
    "    \n",
    "    all_mses.append(mse)\n",
    "\n",
    "print(\"====================================\")\n",
    "print(\"Mean MSE:\", np.mean(all_mses))\n",
    "print(\"Std MSE:\", np.std(all_mses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2344db",
   "metadata": {},
   "source": [
    "## Fine-Tuning the Model\n",
    "\n",
    "We’re now ready to fine-tune the model on the dataset. Without diving into the nitty-gritty of the fine-tuning process, we’ll simply use the `gr00t_finetune.py` script. Run the command below to get started:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02cef3",
   "metadata": {},
   "source": [
    "```bash\n",
    "python scripts/gr00t_finetune.py \\\n",
    "  --dataset-path ./demo_data/robot_sim.PickNPlace \\\n",
    "  --num-gpus 1 \\\n",
    "  --max-steps 500 \\\n",
    "  --output-dir /tmp/gr00t-1/finetuned-model \\\n",
    "  --data-config gr1_arms_only\n",
    "```\n",
    "\n",
    "_To see all available options, run `python scripts/gr00t_finetune.py --help`._\n",
    "\n",
    "The script will save the fine-tuned model in `/tmp/gr00t-1/finetuned-model`. We’ll later load the checkpoint saved at **step 500**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083bd67",
   "metadata": {},
   "source": [
    "### Fine-Tuning Evaluation\n",
    "\n",
    "Now we can evaluate the fine-tuned model by running the policy on the dataset to see how well it performs. We’ll use a utility function to assess the policy on the dataset—similar to the earlier tutorial [1_pretrained_model.ipynb](1_pretrained_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model_path = \"/tmp/gr00t-1/finetuned-model/checkpoint-500\"\n",
    "\n",
    "from gr00t.utils.eval import calc_mse_for_single_trajectory\n",
    "import warnings\n",
    "\n",
    "finetuned_policy = Gr00tPolicy(\n",
    "    model_path=finetuned_model_path,\n",
    "    embodiment_tag=\"new_embodiment\",\n",
    "    modality_config=modality_config,\n",
    "    modality_transform=modality_transform,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "mse = calc_mse_for_single_trajectory(\n",
    "    finetuned_policy,\n",
    "    dataset,\n",
    "    traj_id=0,\n",
    "    modality_keys=[\"right_arm\", \"right_hand\"],   # we will only evaluate the right arm and right hand\n",
    "    steps=150,\n",
    "    action_horizon=16,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "print(\"MSE loss for trajectory 0:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7de56",
   "metadata": {},
   "source": [
    "Awesome! We’ve fine-tuned the model and evaluated it on the dataset. The results show it has mastered the task and now outperforms the pre-trained baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
