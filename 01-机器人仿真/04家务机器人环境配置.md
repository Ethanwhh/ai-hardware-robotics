**家庭整理任务中低级操作的基准评测**

**[论文](https://arxiv.org/abs/2412.13211)** | **[官网](https://arth-shukla.github.io/mshab/)** | **[模型](https://huggingface.co/arth-shukla/mshab_checkpoints)** | **[数据集](https://arth-shukla.github.io/mshab/#dataset-section)** | **[补充材料](https://sites.google.com/view/maniskill-hab)**

---

## 安装与设置

1. **安装环境**
   
   ```bash
   conda create -n mshab python=3.9
   conda activate mshab
   ```

2. **安装 ManiSkill3 与项目代码**
   
   ```bash
   git clone https://github.com/haosulab/ManiSkill.git -b mshab --single-branch
   pip install -e ManiSkill
   pip install -e .  # 可选安装训练/开发依赖：pip install -e .[train,dev]
   ```

3. **下载所需数据集**
   
   ```bash
   for dataset in ycb ReplicaCAD ReplicaCADRearrange; do python -m mani_skill.utils.download_asset "$dataset"; done
   ```

4. **导入环境**
   
   ```python
   import mshab.envs
   ```

---

## [可选] 检查点、数据集和数据生成

- 模型和数据集可从 HuggingFace 获取（约 490GB）：
  
  ```bash
  huggingface-cli login
  
  huggingface-cli download arth-shukla/mshab_checkpoints --local-dir mshab_checkpoints
  
  export MS_ASSET_DIR="~/.maniskill"
  export MSHAB_DATASET_DIR="$MS_ASSET_DIR/data/scene_datasets/replica_cad_dataset/rearrange-dataset"
  
  huggingface-cli download --repo-type dataset arth-shukla/MS-HAB-TidyHouse --local-dir "$MSHAB_DATASET_DIR/tidy_house"
  huggingface-cli download --repo-type dataset arth-shukla/MS-HAB-PrepareGroceries --local-dir "$MSHAB_DATASET_DIR/prepare_groceries"
  huggingface-cli download --repo-type dataset arth-shukla/MS-HAB-SetTable --local-dir "$MSHAB_DATASET_DIR/set_table"
  ```

- 使用脚本生成数据（可自定义轨迹过滤准则）：
  
  ```bash
  bash scripts/gen_dataset.sh
  ```

---

## 快速开始

MS-HAB 提供：

- **评估环境** `SequentialTask-v0`：用于完整任务评估（支持子任务链）

- **训练环境** `[Name]SubtaskTrain-v0`：用于训练单个技能策略，如 `PickSubtaskTrain-v0`

示例代码如下：

```python
import gymnasium as gym
from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv
import mshab.envs
from mshab.envs.planner import plan_data_from_file

task = "tidy_house"
subtask = "pick"
split = "train"

plan_data = plan_data_from_file(REARRANGE_DIR / "task_plans" / task / subtask / split / "all.json")
spawn_data_fp = REARRANGE_DIR / "spawn_data" / task / subtask / split / "spawn_data.pt"

env = gym.make(
    f"{subtask.capitalize()}SubtaskTrain-v0",
    num_envs=252,
    obs_mode="rgbd",
    sim_backend="gpu",
    robot_uids="fetch",
    control_mode="pd_joint_delta_pos",
    reward_mode="normalized_dense",
    render_mode="rgb_array",
    max_episode_steps=200,
    task_plans=plan_data.plans,
    scene_builder_cls=plan_data.dataset,
    spawn_data_fp=spawn_data_fp,
)

venv = ManiSkillVectorEnv(env, max_episode_steps=1000, ignore_terminations=True)
obs, info = venv.reset()
```

---

## 场景与任务自定义

- **场景**：ReplicaCAD 提供84个公寓场景（63训练，21验证）

- **任务计划**：定义任务顺序与目标，如 “Pick → Place”

- **生成数据**：机器人及物体初始状态，由脚本预生成（用于 GPU 模拟时稳定性）

### 简单自定义

- 可只加载部分任务计划调试

- 成功/失败标准可通过 `task_cfgs` 调整（如放置目标的范围）

### 高级自定义

- 任务链可加长（需逻辑合理，如避免“Pick → Pick”）

- 可通过修改配置和使用 `SceneBuilder` 改变对象/场景等

---

## 训练

支持多种算法（SAC、PPO、行为克隆、扩散策略）：

```bash
bash scripts/train_[algo].sh
```

示例：

```bash
python -m mshab.train_sac \
  mshab_checkpoints/rl/tidy_house/pick/all/config.yml \
  algo.gamma=0.8
```

**恢复训练**

```bash
python -m mshab.train_ppo \
  mshab_checkpoints/rl/tidy_house/pick/all/config.yml \
  model_ckpt=mshab_checkpoints/rl/tidy_house/pick/all/policy.pt \
  algo.lr=1e-3
```

---

## 评估

需先下载或生成数据。可使用下列脚本进行完整任务或子任务评估：

```bash
bash scripts/evaluate_sequential_task.sh
```
